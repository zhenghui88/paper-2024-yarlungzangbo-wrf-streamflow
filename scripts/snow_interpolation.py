#!/usr/bin/env python3
"""
Interpolate snow water equivalent data to a new grid using Clough-Tocher interpolation.

This script reads a NetCDF4 file containing snow water equivalent data
(generated by snow_convert_tonc.py), interpolates it to a new grid specified
by a grid definition file, and writes the interpolated data to a new NetCDF4 file.

The source data can have 2D coordinate grids, and the grid definition file must
be a NetCDF4 file with 1D coordinate variables 'lat' and 'lon'.
"""

import argparse
from datetime import UTC, datetime
from pathlib import Path
from typing import cast

import h5netcdf
import numpy as np
from scipy.interpolate import CloughTocher2DInterpolator


def read_source_data(source_file: Path):
    """
    Read snow water equivalent data from the source NetCDF file.

    Args:
        source_file: Path to the source NetCDF file

    Returns:
        tuple: (snow_data, lat, lon, time, metadata)
    """
    with h5netcdf.File(source_file, "r") as f:
        # Read coordinate variables
        if "latitude" in f.variables and "longitude" in f.variables:
            lat = f.variables["latitude"][:]
            lon = f.variables["longitude"][:]
        elif "lat" in f.variables and "lon" in f.variables:
            lat = f.variables["lat"][:]
            lon = f.variables["lon"][:]
        else:
            raise ValueError(
                "Could not find latitude/longitude variables in source file"
            )
        lat = cast(np.ndarray, lat)
        lon = cast(np.ndarray, lon)

        # Read time variable
        if "time" in f.variables:
            time = f.variables["time"][:]
            time_attrs = dict(f.variables["time"].attrs)
        else:
            raise ValueError("Could not find time variable in source file")

        # Read snow data
        if "snow" in f.variables:
            snow_data = f.variables["snow"][:]
            snow_attrs = dict(f.variables["snow"].attrs)
        else:
            raise ValueError("Could not find snow variable in source file")
        snow_data = cast(np.ndarray, snow_data)

        # Read global attributes
        global_attrs = dict(f.attrs)

    metadata = {
        "time_attrs": time_attrs,
        "snow_attrs": snow_attrs,
        "global_attrs": global_attrs,
    }

    return snow_data, lat, lon, time, metadata


def read_target_grid(grid_file: Path):
    """
    Read target grid definition from NetCDF file.

    Args:
        grid_file: Path to the grid definition NetCDF file

    Returns:
        tuple: (target_lat, target_lon)
    """
    with h5netcdf.File(grid_file, "r") as f:
        # Read coordinate variables
        if "lat" in f.variables and "lon" in f.variables:
            target_lat = f.variables["lat"][:]
            target_lon = f.variables["lon"][:]
        elif "latitude" in f.variables and "longitude" in f.variables:
            target_lat = f.variables["latitude"][:]
            target_lon = f.variables["longitude"][:]
        elif "south_north" in f.variables and "west_east" in f.variables:
            target_lat = f.variables["south_north"][:]
            target_lon = f.variables["west_east"][:]
        else:
            raise ValueError(
                "Could not find lat/lon or latitude/longitude variables in grid file"
            )
        target_lat = cast(np.ndarray, target_lat)
        target_lon = cast(np.ndarray, target_lon)

        # Ensure they are 1D
        if target_lat.ndim != 1 or target_lon.ndim != 1:
            raise ValueError("Grid definition coordinates must be 1D arrays")

    return target_lat, target_lon


def interpolate_snow_data(
    snow_data: np.ndarray,
    source_lat: np.ndarray,
    source_lon: np.ndarray,
    target_lat: np.ndarray,
    target_lon: np.ndarray,
):
    """
    Interpolate snow data to the target grid using Clough-Tocher interpolation.

    Args:
        snow_data: Source snow data array (time, lat, lon)
        source_lat: Source latitude coordinates (1D or 2D)
        source_lon: Source longitude coordinates (1D or 2D)
        target_lat: Target latitude coordinates (1D)
        target_lon: Target longitude coordinates (1D)

    Returns:
        np.ndarray: Interpolated snow data (time, target_lat, target_lon)
    """
    n_times = snow_data.shape[0]
    n_target_lat = len(target_lat)
    n_target_lon = len(target_lon)

    # Initialize output array
    interpolated_data = np.full((n_times, n_target_lat, n_target_lon), np.nan)

    # Create meshgrid for target coordinates
    target_lon_2d, target_lat_2d = np.meshgrid(target_lon, target_lat)
    target_points = np.column_stack([target_lon_2d.ravel(), target_lat_2d.ravel()])

    # Handle source coordinates - convert to 2D if 1D
    if source_lat.ndim == 1 and source_lon.ndim == 1:
        source_lon_2d, source_lat_2d = np.meshgrid(source_lon, source_lat)
    elif source_lat.ndim == 2 and source_lon.ndim == 2:
        source_lat_2d = source_lat
        source_lon_2d = source_lon
    else:
        raise ValueError("Source coordinates must be both 1D or both 2D")

    # Create source coordinate points for interpolation
    source_points = np.column_stack([source_lon_2d.ravel(), source_lat_2d.ravel()])

    print(f"Interpolating {n_times} time steps...")
    if source_lat.ndim == 1:
        print(f"Source grid: {len(source_lat)} x {len(source_lon)} (regular)")
    else:
        print(f"Source grid: {source_lat.shape[0]} x {source_lat.shape[1]} (2D)")
    print(f"Target grid: {n_target_lat} x {n_target_lon}")

    # Interpolate each time step
    for t in range(n_times):
        if (t + 1) % 10 == 0 or t == 0:
            print(f"Processing time step {t + 1}/{n_times}")

        # Get data for this time step
        data_2d = snow_data[t, :, :]

        # Skip if all NaN
        if np.all(np.isnan(data_2d)):
            continue

        # Flatten the data values
        data_values = data_2d.ravel()

        # Remove NaN values from both coordinates and data
        valid_mask = ~np.isnan(data_values)
        if not np.any(valid_mask):
            continue

        valid_source_points = source_points[valid_mask]
        valid_data_values = data_values[valid_mask]

        # Create Clough-Tocher interpolator
        interpolator = CloughTocher2DInterpolator(
            valid_source_points, valid_data_values, fill_value=np.nan
        )

        # Interpolate to target grid
        interpolated_flat = interpolator(target_points)
        interpolated_data[t, :, :] = interpolated_flat.reshape(
            n_target_lat, n_target_lon
        )

    return interpolated_data


def write_interpolated_data(
    output_file: Path,
    interpolated_data,
    target_lat,
    target_lon,
    time: list[datetime],
    metadata,
):
    """
    Write interpolated data to a new NetCDF file.

    Args:
        output_file: Path to the output NetCDF file
        interpolated_data: Interpolated snow data
        target_lat: Target latitude coordinates
        target_lon: Target longitude coordinates
        time: Time coordinates from source
        metadata: Metadata dictionary from source
    """
    with h5netcdf.File(output_file, "w") as f:
        # Create dimensions
        f.dimensions["time"] = None
        f.dimensions["latitude"] = len(target_lat)
        f.dimensions["longitude"] = len(target_lon)
        f.resize_dimension("time", len(time))

        # Create coordinate variables
        lat_var = f.create_variable(
            "latitude",
            ("latitude",),
            data=target_lat,
            dtype=np.float64,
            compression="gzip",
        )
        lon_var = f.create_variable(
            "longitude",
            ("longitude",),
            data=target_lon,
            dtype=np.float64,
            compression="gzip",
        )
        time_var = f.create_variable(
            "time",
            ("time",),
            data=time,
            dtype=np.int64,
            compression="gzip",
        )

        # Create snow data variable
        snow_var = f.create_variable(
            "snow",
            ("time", "latitude", "longitude"),
            data=np.maximum(interpolated_data, 0.0),
            dtype=np.float64,
            fillvalue=np.nan,
            compression="gzip",
        )

        # Add coordinate attributes
        lat_var.attrs["units"] = np.bytes_("degrees_north", "ascii")
        lat_var.attrs["long_name"] = np.bytes_("latitude", "ascii")
        lat_var.attrs["standard_name"] = np.bytes_("latitude", "ascii")
        lat_var.attrs["axis"] = np.bytes_("Y", "ascii")

        lon_var.attrs["units"] = np.bytes_("degrees_east", "ascii")
        lon_var.attrs["long_name"] = np.bytes_("longitude", "ascii")
        lon_var.attrs["standard_name"] = np.bytes_("longitude", "ascii")
        lon_var.attrs["axis"] = np.bytes_("X", "ascii")

        # Add time attributes from source
        for key, value in metadata["time_attrs"].items():
            time_var.attrs[key] = value

        # Add snow data attributes from source
        for key, value in metadata["snow_attrs"].items():
            if key == "_FillValue":
                continue
            snow_var.attrs[key] = value

        # Add global attributes from source
        for key, value in metadata["global_attrs"].items():
            f.attrs[key] = value

        # Update history
        now_str = datetime.now(UTC).strftime("%Y-%m-%d %H:%M:%S UTC")
        history_str = f"Clough-Tocher interpolated on {now_str}"
        f.attrs["history"] = np.bytes_(history_str, "ascii")


def main():
    """Main function to handle command line arguments and orchestrate the interpolation."""
    parser = argparse.ArgumentParser(
        description="Interpolate snow water equivalent data to a new grid using Clough-Tocher method"
    )
    parser.add_argument(
        "source_file",
        type=Path,
        help="Path to the source NetCDF file (output from snow_convert_tonc.py)",
    )
    parser.add_argument(
        "grid_file",
        type=Path,
        help="Path to the grid definition NetCDF file with 'lat' and 'lon' variables",
    )
    parser.add_argument(
        "output_file",
        type=Path,
        help="Path to the output NetCDF file",
    )

    args = parser.parse_args()

    # Validate input files exist
    if not args.source_file.exists():
        print(f"Error: Source file {args.source_file} does not exist")
        exit(1)

    if not args.grid_file.exists():
        print(f"Error: Grid file {args.grid_file} does not exist")
        exit(1)

    # Validate output directory exists
    if not args.output_file.parent.exists():
        print(f"Error: Output directory {args.output_file.parent} does not exist")
        exit(1)

    try:
        print("Reading source data...")
        snow_data, source_lat, source_lon, time, metadata = read_source_data(
            args.source_file
        )

        print("Reading target grid...")
        target_lat, target_lon = read_target_grid(args.grid_file)

        print("Interpolating data...")
        interpolated_data = interpolate_snow_data(
            snow_data, source_lat, source_lon, target_lat, target_lon
        )

        print("Writing interpolated data...")
        write_interpolated_data(
            args.output_file, interpolated_data, target_lat, target_lon, time, metadata
        )

        print(f"Successfully interpolated snow data to {args.output_file}")
        print(f"Output grid shape: {len(target_lat)} x {len(target_lon)}")
        print(f"Time steps: {len(time)}")

    except Exception as e:
        print(f"Error: {e}")
        exit(1)


if __name__ == "__main__":
    main()
